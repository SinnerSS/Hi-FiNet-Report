Fault diagnosis in WSNs has been extensively studied using both traditional rule-based/statistical methods and machine learning (ML) techniques. In non-ML approaches, sensors often use fixed thresholds, mathematical models, or combinatorial tests to identify anomalies. Ahmad et al. proposed Kalman filtering as a lightweight anomaly detector in WSNs, but pure Kalman models degrade under fluctuating conditions \cite{Ahmad2024}. These methods typically require hand-tuned parameters and can yield high false alarms when environmental noise is high \cite{Muhammed2017, Zhang2018}.  In contrast, ML-based approaches learn patterns from data. Supervised classifiers (SVMs, decision trees, neural networks, etc.) and unsupervised models (clustering, autoencoders, one-class SVMs, etc.) have become popular for fault detection. ML methods can automatically capture complex patterns in sensor readings, improving outlier detection without explicit rules. For instance, Zidi et al. use an SVM on a labeled TelosB temperature/humidity dataset, and Noshad et al. evaluate six classifiers (SVM, RF, CNN, etc.) on real WSN data. These studies report that ML models often achieve high detection accuracy and F1-scores, but require representative training data and incur higher computational cost. In summary, model-based methods (thresholds, filters) are simple but inflexible, while data-driven methods (ML classifiers and deep networks) offer greater adaptability at the cost of complexity.

WSN fault detection architectures are typically classified as centralized, distributed, or self-diagnosis (self-supervision) schemes. In centralized schemes, all sensor nodes send status reports or readings to a base station (sink), which performs fault analysis. This simplifies the detection logic but incurs high communication overhead: as the network scales, the sink must process many messages, leading to increased latency and limited real-time applicability. By contrast, self-diagnosis has each node monitor its own status (e.g., battery level or sensor output) and detect local faults. Such methods achieve very low detection latency and eliminate extra messaging, but they only catch persistent or easily modelled faults and rely on fixed thresholds or energy models. Distributed strategies involve neighbors or cluster-heads collaborating to detect faults. For example, nodes can mutually cross-check readings or vote on anomalies, and cluster-heads can aggregate data for local inference. These decentralized methods improve detection accuracy (errors are confirmed by multiple nodes) and scale better via clustering, but they consume extra energy and bandwidth for peer communication. In particular, Adday et al. note that cluster-based diagnosis can reduce communication relative to flat schemes and improve scalability. In summary, centralized methods are easy to implement but suffer from latency, self-diagnosis is fast but limited in scope, and distributed schemes balance accuracy and energy at the expense of complexity.

Recent advances have explored hierarchical and hybrid techniques that fuse multiple levels of analysis and feature types. Hierarchical WSN architectures (e.g. clustering) naturally allow multi-stage diagnosis, where cluster-heads perform local detection and report to higher layers. Hybrid methods aim to combine complementary models; for example, Ahmad et al. propose an Online Adaptive Kalman Filter that dynamically adjusts its parameters for real-time anomaly detection. They demonstrate that a static Kalman model is fast but yields many false alarms under variable signals. To overcome such limitations, some works combine Kalman filters with machine learning: one cited example uses a Kalman filter together with an autoencoder to improve estimation and detection accuracy. Likewise, Shi et al. emphasize that sensor data possess strong temporal and spatial correlations, and that fault features should capture both aspects. These efforts suggest a trend toward spatio-temporal fusion: e.g. using time-series prediction at each node together with spatial neighbor-consensus. Nevertheless, truly integrated models that jointly leverage per-node temporal dynamics and network-wide spatial context are still rare in the literature. HiFiNet is motivated by this gap, seeking to hierarchically combine temporal modeling (e.g. autoregressive encoding at nodes) with spatial modeling (e.g. graph-based fusion across nodes).
